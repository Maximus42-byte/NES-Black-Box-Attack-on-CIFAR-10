{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Student Number:Mahdi Saieedi\n",
        "\n",
        "##Name:401207254"
      ],
      "metadata": {
        "id": "Ar1V8Q3ASeqy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRrvAChBVXEf"
      },
      "source": [
        "#**Notes**\n",
        "In this notebook you are going to implement [NES](https://arxiv.org/pdf/1804.08598.pdf) blackbox attack and test in on Cifar10. First, you must implement the provided functions. Then you must test the attack and report the average number of queries and the success rate of the attack. You can define as many additional functions as you want. If you want to alter the structure of the provided code, please do as minimally as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Dependencies**"
      ],
      "metadata": {
        "id": "9bUw1fnES7vn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ovEZsWD5K_Ey"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "from typing import Type\n",
        "import numpy as np\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision.models import resnet18"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Defining the Model and Dataloader**\n",
        "Here the link to a ResNet18 checkpoint is provided. Please use this checkpoint."
      ],
      "metadata": {
        "id": "k8mt4gp2S-c6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TqMGQOsaK9Sf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2672eb94-bd23-47fd-de50-a3010620ce43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "transform = transforms.Compose([transforms.RandomCrop(32, padding=4), transforms.RandomHorizontalFlip(), transforms.ToTensor(),])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='/content/cifar10/', train = True, download = True, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='/content/cifar10/', train = False, download = True, transform = transforms.Compose([transforms.ToTensor(),]))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False, num_workers = 2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(nn.Module):\n",
        "  def __init__(self, num_cls):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        *list(resnet18(weights=None).children())[:-2])\n",
        "\n",
        "    self.fc = nn.Linear(512, num_cls)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = torch.flatten(x, start_dim=1)\n",
        "    logits = self.fc(x)\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "_oKXfOvsB7Dw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1-k2y76KAtvFxXDVPMDIzXtVa0sDgF0MQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkfqulEKPraZ",
        "outputId": "dc1048a9-207e-46a2-e9a4-41ab499248f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-k2y76KAtvFxXDVPMDIzXtVa0sDgF0MQ\n",
            "From (redirected): https://drive.google.com/uc?id=1-k2y76KAtvFxXDVPMDIzXtVa0sDgF0MQ&confirm=t&uuid=95704202-efec-4852-8916-27acf7d6709b\n",
            "To: /content/resnet18_cifar10_model.pt\n",
            "100% 44.8M/44.8M [00:00<00:00, 67.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "CIFAR10_model_PATH = \"/content/resnet18_cifar10_model.pt\"\n",
        "state_dict = torch.load(CIFAR10_model_PATH, map_location=device)\n",
        "\n",
        "\n",
        "model = ResNet18(10).to(device)\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the model on the test set: {100 * correct / total}')"
      ],
      "metadata": {
        "id": "4Q1VAHu1BwM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0955e5-ece2-4bfc-870d-3d476123f277"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test set: 83.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isdk2N3kZE4k"
      },
      "source": [
        "# **Natural Evolutionary Strategies (NES)**\n",
        "\n",
        "complete the functions in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KOtCzRz9VS8i"
      },
      "outputs": [],
      "source": [
        "def estimate_grad(model, images, labels, search_variance, n, device):\n",
        "    \"\"\"\n",
        "    NES Gradient Estimate\n",
        "\n",
        "    inputs:\n",
        "            - model: the target model (only used for computing the loss)\n",
        "            - images: Tensor containing images. size: [number of images, 3, image_dim, image_dim]\n",
        "            - labels: Tensor containing the original labels of images.\n",
        "            - search_variance: sigma\n",
        "            - n: number of samples to estimate the gradient\n",
        "\n",
        "    outputs:\n",
        "            - g: estimated gradients. has similar shape as images.\n",
        "\n",
        "    Guide:  - Define g with initial value 0.\n",
        "            - for n iterations do:\n",
        "                - Define a tensor of random Gaussian noise with the input image shape (use torch.randn)\n",
        "                - Divide this tensor by (sqrt(image_dim*image_dim*3)). (we do this due to the properties of gaussian distribution in high-dimensional space.)\n",
        "                - Compute the gradient of the loss with finite difference method using the defined noise tensor.\n",
        "                - Add the comupted value to g\n",
        "    \"\"\"\n",
        "\n",
        "    #Your Code Goes Here (15 pt.)\n",
        "\n",
        "    # Initialize the gradient estimate with zeros\n",
        "    g = torch.zeros_like(images).to(device)\n",
        "    batch_size = images.size(0)\n",
        "    image_dim = images.size(2)  # Assuming square images\n",
        "    noise_shape = images.shape\n",
        "\n",
        "    # Calculate the normalization factor for the noise\n",
        "    normalization_factor = (image_dim * image_dim * 3) ** 0.5\n",
        "\n",
        "    # Set the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for _ in range(n):\n",
        "      # Generate random Gaussian noise\n",
        "      noise = torch.randn(noise_shape, device= device) / normalization_factor\n",
        "\n",
        "      # Perturb the images with noise\n",
        "      perturbed_images_plus = images + search_variance * noise\n",
        "      perturbed_images_minus = images - search_variance * noise\n",
        "\n",
        "      # Compute the loss for the perturbed images\n",
        "      with torch.no_grad():\n",
        "        logits_plus = model(perturbed_images_plus)\n",
        "        logits_minus = model(perturbed_images_minus)\n",
        "\n",
        "      # Compute the loss values\n",
        "      loss_plus = F.cross_entropy(logits_plus, labels, reduction='none')\n",
        "      loss_minus = F.cross_entropy(logits_minus, labels, reduction='none')\n",
        "\n",
        "      # Compute the finite difference gradient estimate\n",
        "      gradient_estimate = (loss_plus - loss_minus).view(batch_size, 1, 1, 1) * noise / (2 * search_variance)\n",
        "\n",
        "      # Accumulate the gradient estimate\n",
        "      g += gradient_estimate\n",
        "\n",
        "    return g\n",
        "\n",
        "\n",
        "def generate_attacks(model, images, labels, args, device):\n",
        "    '''\n",
        "    The process for generating blackbox adversarial examples. Implement for l_infty attack.\n",
        "\n",
        "    inputs:\n",
        "            - model: The target model\n",
        "            - images: Tensor containing images of a batch. size: [batch_size, 3, image_dim, image_dim]\n",
        "            - labels: Tensor containing the original labels of images. size: [batch_size, num_classes]\n",
        "\n",
        "    outputs:\n",
        "            - attacks: Must have the same shape as images.\n",
        "            - total_queries: number of queries till a successful attack for each sample\n",
        "            - success: Flag showing if each attack was successful or not.\n",
        "    '''\n",
        "    # Parameters\n",
        "    epsilon = args['delta']  # Maximum perturbation\n",
        "    alpha = args['epsilon']  # Step size\n",
        "    max_queries = args['max_queries']\n",
        "    num_samples = images.shape[0]\n",
        "\n",
        "    total_queries = torch.zeros(num_samples).to(device)   #counter for number of queries. must be stopped for a sample when the attack for that sample is successful.\n",
        "    success = torch.zeros(num_samples).to(device)          #boolean tensor indicating whether the attack is successfull or not.\n",
        "    attacks = images.clone().to(device)\n",
        "\n",
        "\n",
        "    #Here we want to generate PGD adversarial examples. we continue until we are out of queries.\n",
        "\n",
        "    #Must Check not to have more queries than \"max_queries\" (Of course, you must update the value of total_queries)\n",
        "    while  torch.any(total_queries < max_queries) and torch.any(success == 0):\n",
        "        #Your Code Goes Here (15 pt)\n",
        "        # Generate NES gradient estimates\n",
        "        gradients = estimate_grad(model, attacks, labels, args['search_variance'], args['gradient_num_samples'], device)\n",
        "\n",
        "        # Perform PGD update\n",
        "        perturbations = alpha * torch.sign(gradients)\n",
        "        attacks = attacks + perturbations\n",
        "        attacks = torch.clamp(attacks, images - epsilon, images + epsilon)  # Project back into the epsilon ball\n",
        "        attacks = torch.clamp(attacks, 0, 1)  # Ensure the perturbed image is still valid (pixel values between 0 and 1)\n",
        "\n",
        "        # Evaluate the model on the perturbed images\n",
        "        outputs = model(attacks)\n",
        "        _, predicted = outputs.max(1)\n",
        "        #_, original = labels.max(1)\n",
        "\n",
        "        # Update success and query counts\n",
        "        successful_attacks = (predicted != labels).float()\n",
        "        success = torch.max(success, successful_attacks)\n",
        "        total_queries += 1\n",
        "\n",
        "        # Ensure that we stop updating total_queries for already successful attacks\n",
        "        total_queries = torch.min(total_queries, max_queries * (success == 0) + total_queries * (success == 1))\n",
        "\n",
        "    return attacks, total_queries, success"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  args = {'epsilon': 0.3, 'alpha': 0.01, 'max_queries': 100, 'search_variance': 0.1, 'n': 50}"
      ],
      "metadata": {
        "id": "uiW5QDW1PS9l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize model and move it to the appropriate device\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = model.to(device)"
      ],
      "metadata": {
        "id": "Ckf7xWaDTkN9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# attacks, total_queries, success = generate_attacks(model, images, labels, args)"
      ],
      "metadata": {
        "id": "0eGIrGwpPV8k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWdQXoR3YS58"
      },
      "source": [
        "# **Attack Report**\n",
        "\n",
        "Report the success rate and average number of qureies for blackbox $l_∞$ PGD attacks for $\\sigma \\in \\{0.001, 0.01\\}$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Cr72hNYhXO7y"
      },
      "outputs": [],
      "source": [
        "args = {'max_queries': 200, #maximum number of queries\n",
        "        'search_variance': 0.01,  #sigma\n",
        "        'epsilon': 0.01,    #step size in pgd\n",
        "        'delta': 0.05,      #radius on which the attack must be projected\n",
        "        'batch_size': 40,\n",
        "        'gradient_num_samples': 15, #number of samples used for estimating the gradients\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='/content/cifar10/', train = False, download = True, transform = transforms.Compose([transforms.ToTensor(),]))\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = args['batch_size'], shuffle = False, num_workers = 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oev0saAim6R4",
        "outputId": "df85f9cb-d79c-40b5-bf44-ce55bdb9f8d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###################################\n",
        "#Your Code Goes Here (5 pt)\n",
        "for i, data in enumerate(testloader):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    attacks, total_queries, success = generate_attacks(model, images, labels, args, device)\n",
        "\n",
        "    # Analyze the results\n",
        "    print(f\"Batch {i+1}\")\n",
        "    print(f\"Total Queries: {total_queries}\")\n",
        "    print(f\"Success Rate: {success.mean().item()}\")\n",
        "\n",
        "    # Optionally save the adversarial examples for further analysis\n",
        "    # torch.save(attacks, f\"adversarial_examples_batch_{i+1}.pth\")\n",
        "\n",
        "    if i == 0:  # Process only the first batch for demonstration purposes\n",
        "        break\n",
        "\n",
        "####################################"
      ],
      "metadata": {
        "id": "IIVBuKQiXMLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "56cb4938-d322-472b-df95-f0a444608947"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1\n",
            "Total Queries: tensor([200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200., 200.,\n",
            "        200., 200., 200., 200., 200., 200., 200., 200.])\n",
            "Success Rate: 0.8999999761581421\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}